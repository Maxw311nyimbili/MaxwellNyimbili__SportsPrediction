# -*- coding: utf-8 -*-
"""MAXWELLNYIMBILI._SportsPrediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MaNCaIylTeRUltu-ltYJa2RSEBFLVGK0

## LOAD THE FILE
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split


df=pd.read_csv('/content/drive/My Drive/Colab Notebooks/content/male_players (legacy).csv', na_values='-')

"""## 1. DATA PREPARATION & FEATURE EXTRACTION

#### ***a) Removing columns with null rows greater than 40% of all the rows***
"""

# Features with more than 40% missing values should be dropped
L_more = []
L_less = []
for i in df.columns:
    if((df[i].isnull().sum()) < (0.4*(df.shape[0]))):
        L_less.append(i)
    else:
        L_more.append(i)

df = df[L_less]

"""#### ***b) Selecting relevant features based on problem scope***"""

# Separating the data
import numpy as np
numeric_data = df.select_dtypes(include=np.number)
non_numeric = df.select_dtypes(include = ['object'])

# Drop irrelevant numerical-columns
numeric_data.drop(['player_id', 'fifa_version', 'fifa_update', 'club_team_id', 'club_jersey_number', 'club_contract_valid_until_year', 'nationality_id'], axis=1, inplace=True)

# Drop irrelevant non-numerical-columns
non_numeric.drop(['player_url', 'fifa_update_date'], axis=1, inplace=True)

"""### ***c) Imputing***"""

# IMPUTE THE NUMERIC DATA
# MULTIVARIABLE IMPUTATION
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
imp = IterativeImputer(max_iter = 10, random_state=0)
numeric_data = pd.DataFrame(np.round(imp.fit_transform(numeric_data)), columns=numeric_data.columns)

# Mode imputation for NON-NUMERIC DATA
non_numeric['club_name'].fillna(df['club_name'].mode()[0], inplace=True)
non_numeric['league_name'].fillna(df['league_name'].mode()[0], inplace=True)
non_numeric['club_position'].fillna(df['club_position'].mode()[0], inplace=True)
non_numeric['club_joined_date'].fillna(df['club_joined_date'].mode()[0], inplace=True)

"""### ***d) Encoding Non-numerical Data***

##### ***i) Separating Binary and Non-Binary non-numerical data***
"""

# NON-BINARY SUBSET
indices_to_exclude = [9, 13]
columns_to_keep = non_numeric.columns.difference(non_numeric.columns[indices_to_exclude])

non_binary = non_numeric[columns_to_keep]

# BINARY SUBSET
binary = non_numeric.iloc[:,9:13].iloc[:, [0, -1]]
non_binary.columns

"""##### ***ii) LABEL ENCODING FOR BINARY NON-NUMERICAL DATA***"""

from sklearn.preprocessing import LabelEncoder # import the LabelEncoder
label_encoder = LabelEncoder() # Instantiation of the LabelEncoder

# Encode binary variables
binary['preferred_foot_encoded'] = label_encoder.fit_transform(df['preferred_foot'])
binary['real_face_encoded'] = label_encoder.fit_transform(df['real_face'])

binary_encoded = binary.iloc[:,2:]
binary_encoded #<--- non-comment to see output

"""### MERGING THE DATA"""

full_merged = pd.concat([numeric_data, binary_encoded], axis=1) # merging the binary-non numerical data and the numerical data
# full_merged  #<--- non-comment to see output

"""## 2. Create Feature Subsets Showing Maximum Correlation with the Dependent Variable"""

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
sns.heatmap(full_merged.corr(), annot=False, cmap='coolwarm', center=0)
plt.title('Correlation Matrix of Scaled Features')
plt.show()

# Calculate correlation with the target variable 'overall'
correlation_matrix = full_merged.corr()

# Calculate correlations with the target variable "overall"
correlations = full_merged.corr()['overall'].sort_values(ascending=False)

# Select features with a high correlation with 'overall'
high_correlation_features = correlations[abs(correlations) > 0.4].index.tolist()

# Create a subset with the selected features
subset_df = full_merged[high_correlation_features]

subset_df.head()

"""##Scaling the independent Variables"""

from sklearn.preprocessing import StandardScaler

# Separate the independent variables and the target variable
X = subset_df.drop('overall', axis=1)
y = subset_df['overall']

# Scale the independent variables
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Combine scaled independent variables with the target variable for visualization if needed
scaled_df = pd.DataFrame(X_scaled, columns=X.columns)
scaled_df['overall'] = y.reset_index(drop=True)
scaled_df.head()

"""## 3. Create and Train a Suitable Machine Learning Model with Cross-Validation

#### Initialize the models and Definitions of the hyperparameters
"""

from sklearn.experimental import enable_halving_search_cv
from sklearn.model_selection import RandomizedSearchCV, HalvingGridSearchCV, train_test_split, KFold
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error

# Initialize models
rf_model = RandomForestRegressor(random_state=42)
xgb_model = XGBRegressor(random_state=42)
gbr_model = GradientBoostingRegressor(random_state=42)

# Hyperparameter grids
rf_param_grid = {
    'n_estimators': [50, 100, 200, 300],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}


xgb_param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [3, 6],
    'learning_rate': [0.01, 0.1],
    'subsample': [0.8, 1]
}

gbr_param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [3, 6],
    'learning_rate': [0.01, 0.1]
}

"""#### Grid Search With Cross Validation"""

# HalvingGridSearchCV
kfold = KFold(n_splits=3, shuffle=True, random_state=42)

# RandomForest Halving Grid Search
rf_halving_search = HalvingGridSearchCV(estimator=RandomForestRegressor(random_state=42),
                                        param_grid=rf_param_grid,
                                        factor=2,
                                        scoring='neg_mean_absolute_error',
                                        n_jobs=-1,
                                        cv=kfold)
rf_halving_search.fit(X_scaled, y)
print("Best parameters for RandomForest: ", rf_halving_search.best_params_)
print("Best cross-validation MAE for RandomForest: ", -rf_halving_search.best_score_)

# XGBoost Halving Grid Search
xgb_halving_search = HalvingGridSearchCV(estimator=XGBRegressor(random_state=42),
                                         param_grid=xgb_param_grid,
                                         factor=2,
                                         scoring='neg_mean_absolute_error',
                                         n_jobs=-1,
                                         cv=kfold)
xgb_halving_search.fit(X_scaled, y)
print("Best parameters for XGBoost: ", xgb_halving_search.best_params_)
print("Best cross-validation MAE for XGBoost: ", -xgb_halving_search.best_score_)

# GradientBoosting Halving Grid Search
gbr_halving_search = HalvingGridSearchCV(estimator=GradientBoostingRegressor(random_state=42),
                                         param_grid=gbr_param_grid,
                                         factor=2,
                                         scoring='neg_mean_absolute_error',
                                         n_jobs=-1,
                                         cv=kfold)
gbr_halving_search.fit(X_scaled, y)
print("Best parameters for GradientBoosting: ", gbr_halving_search.best_params_)
print("Best cross-validation MAE for GradientBoosting: ", -gbr_halving_search.best_score_)

"""#### Train and Evaluate Best Models on Test Set"""

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Train the best models on the entire training set
best_rf_model = rf_halving_search.best_estimator_
best_xgb_model = xgb_halving_search.best_estimator_
best_gbr_model = gbr_halving_search.best_estimator_

best_rf_model.fit(X_train, y_train)
best_xgb_model.fit(X_train, y_train)
best_gbr_model.fit(X_train, y_train)

# Make predictions on the test set
rf_predictions = best_rf_model.predict(X_test)
xgb_predictions = best_xgb_model.predict(X_test)
gbr_predictions = best_gbr_model.predict(X_test)

# Evaluate the models using MAE
rf_test_mae = mean_absolute_error(y_test, rf_predictions)
xgb_test_mae = mean_absolute_error(y_test, xgb_predictions)
gbr_test_mae = mean_absolute_error(y_test, gbr_predictions)

print("RandomForest Test MAE: ", rf_test_mae)
print("XGBoost Test MAE: ", xgb_test_mae)
print("GradientBoosting Test MAE: ", gbr_test_mae)

"""### Performing Feature importance"""

import matplotlib.pyplot as plt
import numpy as np

# Assuming best_rf_model is the best RandomForest model after fine-tuning
feature_importances = best_rf_model.feature_importances_
features = X.columns

# Sort feature importances in descending order
indices = np.argsort(feature_importances)[::-1]

# Plot the feature importances
plt.figure(figsize=(12, 6))
plt.title("Feature Importance")
plt.bar(range(X.shape[1]), feature_importances[indices], align="center")
plt.xticks(range(X.shape[1]), [features[i] for i in indices], rotation=90)
plt.xlabel('Features')
plt.ylabel('Importance Score')
plt.show()

"""#### Select the top five features based on the importance scores in the diagram above"""

# Select top N important features
top_n_features = 5
important_features = [features[i] for i in indices[:top_n_features]]
print(important_features)
# Update X and X_scaled to keep only the important features
X_important = subset_df[important_features]
X_scaled_important = scaler.fit_transform(X_important)

# Split the updated data into training and testing sets
X_train_important, X_test_important, y_train_important, y_test_important = train_test_split(X_scaled_important, y, test_size=0.2, random_state=42)

subset_df[important_features].describe()

"""#### Train the random forest model with the important features subset"""

from sklearn.metrics import mean_absolute_error, mean_squared_error
# Train the RandomForest model again with important features
rf_model_important = RandomForestRegressor(n_estimators=best_rf_model.n_estimators,
                                           max_depth=best_rf_model.max_depth,
                                           min_samples_split=best_rf_model.min_samples_split,
                                           random_state=42)
rf_model_important.fit(X_train_important, y_train_important)

# Make predictions on the test set
rf_predictions_important = rf_model_important.predict(X_test_important)

# Evaluate the model using MAE and RMSE
rf_test_mae_important = mean_absolute_error(y_test_important, rf_predictions_important)
rf_test_rmse_important = np.sqrt(mean_squared_error(y_test_important, rf_predictions_important))

print("RandomForest Test MAE with Important Features: ", rf_test_mae_important)
print("RandomForest Test RMSE with Important Features: ", rf_test_rmse_important)

"""### 4. Measure the Model's Performance and Fine-Tune"""

from sklearn.model_selection import RandomizedSearchCV, train_test_split, KFold
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np

# Smaller hyperparameter grid for faster search
rf_param_grid = {
    'n_estimators': [50, 100],
    'max_depth': [10, 20],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2]
}

# Randomized Search with Cross-Validation
n_iter_search = 20  # Reduce the number of iterations

rf_random_search_important = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=42),
                                                param_distributions=rf_param_grid,
                                                n_iter=n_iter_search,
                                                cv=kfold,
                                                scoring='neg_mean_absolute_error',
                                                n_jobs=-1,
                                                random_state=42)
rf_random_search_important.fit(X_train_important, y_train_important)

print("Best parameters for RandomForest: ", rf_random_search_important.best_params_)
print("Best cross-validation MAE for RandomForest: ", -rf_random_search_important.best_score_)

# Train the best RandomForest model with important features
best_rf_model_important = rf_random_search_important.best_estimator_
best_rf_model_important.fit(X_train_important, y_train_important)

# Make predictions on the test set
rf_predictions_important = best_rf_model_important.predict(X_test_important)

# Evaluate the model using MAE and RMSE
rf_test_mae_important = mean_absolute_error(y_test_important, rf_predictions_important)
rf_test_rmse_important = np.sqrt(mean_squared_error(y_test_important, rf_predictions_important))

print("RandomForest Test MAE with Important Features (after fine-tuning): ", rf_test_mae_important)
print("RandomForest Test RMSE with Important Features (after fine-tuning): ", rf_test_rmse_important)

"""## 5. Use the data from another season(players_22) which was not used during the training to test how good is the model."""

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np
from sklearn.ensemble import RandomForestRegressor

def evaluate_model_with_new_data(filename, best_rf_model, important_features, scaler):
    # Load the new dataset
    df = pd.read_csv(filename)  # Modify as needed based on your file format

    # Assuming 'overall' is the target variable
    X_22 = df[important_features]  # Use the same important features

    # Impute missing values in X_22 if any
    imputer = SimpleImputer(strategy='mean')  # You can use other strategies as well
    X_22_imputed = imputer.fit_transform(X_22)

    # Scale the independent variables using the provided scaler
    X_scaled_22 = scaler.transform(X_22_imputed)  # Assuming 'scaler' is already fitted

    # Make predictions using the best RandomForest model
    rf_predictions_22 = best_rf_model.predict(X_scaled_22)

    # Calculate evaluation metrics (MAE and RMSE)
    # Assuming 'y_22' is the actual target values from the new dataset
    y_22 = df['overall']  # Adjust this based on your dataset structure

    mae_22 = mean_absolute_error(y_22, rf_predictions_22)
    rmse_22 = np.sqrt(mean_squared_error(y_22, rf_predictions_22))

    # Display informative messages
    print(f"Evaluation results for dataset '{filename}':")
    print(f"Mean Absolute Error (MAE): {mae_22:.4f}")
    print(f"Root Mean Squared Error (RMSE): {rmse_22:.4f}")
    print("\nPredictions:")
    print(rf_predictions_22)

    return rf_predictions_22, mae_22, rmse_22

# Example usage:
# Assuming 'best_rf_model_important', 'important_features', and 'scaler' are defined previously
filename = '/content/drive/My Drive/Colab Notebooks/content/players_22.csv'  # Replace with your file path
predictions, mae, rmse = evaluate_model_with_new_data(filename, best_rf_model_important, important_features, scaler)

"""***CONCLUSION***: The values of 0.4002 for MAE and 0.7729 for RMSE suggest that the model's predictions are relatively close to the actual values on average.
These metrics provide confidence that the model is making predictions with reasonable accuracy.

### SAVE THE MODEL AS A PICKLE FILE
"""

import joblib

# Assuming best_rf_model is your trained RandomForestRegressor model
filename = '/content/drive/My Drive/Colab Notebooks/content/rf_model.pkl'
joblib.dump(best_rf_model_important, filename)

